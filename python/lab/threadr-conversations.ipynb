{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "%#%%\n",
    "pip install neo4j sentence_transformers pandas nltk hdbscan spacy matplotlib wordcloud pyLDAvis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb3b3d97f4380b37"
  },
  {
   "cell_type": "markdown",
   "id": "727fb704df2cbfe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build our dataset from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47932ddc9b0b594",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import textwrap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "NEO4J_URI = \"bolt://neo4j.neo4j.svc.cluster.local\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = 'neo4j'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8e87f9f459798",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "auth = (\"neo4j\", \"keZSjc1CaHTakP\")\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=auth) as driver:\n",
    "    driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a27e75fddfaeba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to execute the query and return results as a pandas DataFrame\n",
    "def get_chat_logs_as_dataframe(driver):\n",
    "    query = \"\"\"\n",
    "    MATCH (m:Message)-[:POSTED_IN]->(c:Channel), (u:User)-[:SENT]->(m)\n",
    "    OPTIONAL MATCH (m)-[:MENTIONED]->(mentioned:User)\n",
    "    RETURN u.name AS user, c.name AS channel, m.timestamp AS timestamp, m.content AS message\n",
    "    ORDER BY m.timestamp DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        results = session.run(query)\n",
    "        \n",
    "        # Convert results to a DataFrame\n",
    "        chat_logs_df = pd.DataFrame([record.data() for record in results])\n",
    "        \n",
    "        # Optionally, you can save the DataFrame to a CSV file for easy use\n",
    "        chat_logs_df.to_csv(\"chat_logs.csv\", index=False)\n",
    "        \n",
    "        print(\"Chat logs saved to chat_logs.csv\")\n",
    "        \n",
    "        return chat_logs_df\n",
    "\n",
    "# Call the function to get chat logs as a pandas DataFrame\n",
    "chat_logs_df = get_chat_logs_as_dataframe(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc96315c51ea7c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Break the chat logs into conversational contexts\n",
    "\n",
    "## Possible Approaches:\n",
    "\n",
    "1. **Clustering**: Use Clustering algorithms to group the chat logs into conversational contexts,\n",
    "like K-Means or DBSCAN. We'll use the `message` column as the feature to cluster on.\n",
    "2. **Time-based**: Group chat logs based on a time window, like every 5 minutes.\n",
    "3. **User-based**: Group chat logs based on the user who sent the message.\n",
    "4. **Channel-based**: Group chat logs based on the channel where the message was posted.\n",
    "5. **Sequential**: Group chat logs based on the order they were posted.\n",
    "6. **Sequence Labeling**: Use Sequence Labeling models to predict the start and end of each conversation, like Named Entity Recognition (NER) models, Conditional Random Fields (CRFs), Hidden Markov Model (HMM) or Long Short-Term Memory (LSTM) networks to label each message with a conversation ID. To do this, we need to train our model on labeled data to learn the conversational patterns that distinguish between different conversational threads. We can use this model to label new messages automatically.\n",
    "7. **Transformer Based Methods**: Use transformer-based models like BERT, GPT-2, or RoBERTa to generate embeddings for each message and cluster them based on the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing and Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f39bf6721f324724"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402d8fa16bbf26",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic text cleaning and preprocessing\n",
    "# You might want to expand this with more sophisticated cleaning\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message'].str.lower().str.replace('[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove stop words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcb48559721da5e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e96b2445caa154",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5a26b6ac3df09d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cd6fd3e82d750fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lemmatize_text)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eff047b0b725848",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing frequent but unimportant words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cecd0bd3855555ad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# build frequent_words\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize the cleaned messages into lists of words\n",
    "chat_logs_df['tokens'] = chat_logs_df['message_clean'].str.split()\n",
    "\n",
    "# Flatten the list of token lists into a single list\n",
    "all_words = [word for tokens in chat_logs_df['tokens'] for word in tokens]\n",
    "\n",
    "# Count the words\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Set a frequency threshold\n",
    "frequency_threshold = 100  # This is just an example value\n",
    "\n",
    "# Filter words that meet or exceed the threshold\n",
    "frequent_words = {word for word, count in word_counts.items() if count >= frequency_threshold}\n",
    "\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in frequent_words]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bb2b5a7ce4e8677",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing rare words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1a6179a7ea3981f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set a frequency threshold for rare words\n",
    "#rare_threshold = 2  # Example: words appearing 2 times or less\n",
    "\n",
    "# Filter words that are equal to or below the threshold\n",
    "#rare_words = {word for word, count in word_counts.items() if count <= rare_threshold}\n",
    "\n",
    "#chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in rare_words]))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad0acc4961e0f0c7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7635ad8036fa7397",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5826dd17cc133",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "message_embeddings = model.encode(chat_logs_df['message_clean'].tolist(), show_progress_bar=True)\n",
    "print(\"Embeddings generated successfully!\")\n",
    "\n",
    "# verify the shape of the embeddings\n",
    "print(message_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151f514a46873f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cluster the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39577374d77b0533",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "# Normalize embeddings to improve clustering\n",
    "message_embeddings_normalized = normalize(message_embeddings)\n",
    "\n",
    "# Clustering with HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, gen_min_span_tree=True)\n",
    "cluster_labels = clusterer.fit_predict(message_embeddings_normalized)\n",
    "\n",
    "# Add cluster labels to your DataFrame\n",
    "chat_logs_df['cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1af0feceb6a96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyze the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc71864cf3374d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore the number of messages per cluster\n",
    "print(chat_logs_df['cluster'].value_counts())\n",
    "\n",
    "# Inspect a specific cluster\n",
    "#print(chat_logs_df[chat_logs_df['cluster'] == 0])\n",
    "\n",
    "# Group the DataFrame by the 'cluster' column\n",
    "grouped_df = chat_logs_df.groupby('cluster')\n",
    "\n",
    "# Iterate through each group\n",
    "for cluster_label, group in grouped_df:\n",
    "    print(f\"Cluster: {cluster_label}\")\n",
    "    print(group)  # 'group' is a DataFrame containing only the rows from this cluster\n",
    "    # You can perform further analysis or processing on each group here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample messages from each cluster"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "466073e096df803c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b8cf1ffff4919",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cluster in sorted(chat_logs_df['cluster'].unique()):\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    sample_texts = chat_logs_df[chat_logs_df['cluster'] == cluster]['message'].sample(n=5)\n",
    "    for text in sample_texts:\n",
    "        print(f\"- {text}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keyword and Phrase analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80d8dc5843ff0475"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for cluster in sorted(chat_logs_df['cluster'].unique()):\n",
    "    words = [word for message in chat_logs_df[chat_logs_df['cluster'] == cluster]['message_clean'] for word in message.split()]\n",
    "    word_counts = Counter(words)\n",
    "    print(f\"Cluster {cluster} common words: {word_counts.most_common(10)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0110df8fe0b3dbd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Cluster size distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26e8187730f4d606",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cluster_sizes = chat_logs_df.groupby('cluster').size()\n",
    "cluster_sizes.plot(kind='bar')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Cluster Size Distribution')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e793639b7ea35f2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word Clouds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "850768370d2dbfed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "for cluster in sorted(chat_logs_df['cluster'].unique()):\n",
    "    text = \" \".join(message for message in chat_logs_df[chat_logs_df['cluster'] == cluster]['message_clean'])\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(text)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster}\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76a324337a43e794",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Topic Modeling\n",
    "\n",
    "Apply topic modeling techniques like Latent Dirichlet Allocation (LDA) within each cluster to discover subtopics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf4a4c13691e3d84"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster -1:\n",
      "Topic 0:\n",
      "movie mayan sig labor lime need year look arnold human\n",
      "Topic 1:\n",
      "sig slave time risk historical easter gallon work reception procedure\n",
      "Topic 2:\n",
      "watch let calorie genre pho place thing feel usdt holland\n",
      "Topic 3:\n",
      "long town people egg think apocalypto wake tie hate baseball\n",
      "Topic 4:\n",
      "fuel uranium rod like cost sig let spend construct involve\n",
      "\n",
      "Cluster 0:\n",
      "Topic 0:\n",
      "dusk fe2 place buy coin trans ruin try day believe\n",
      "Topic 1:\n",
      "dusk coin ruin trans try awareness day believe fe2 doge\n",
      "Topic 2:\n",
      "coin dot dusk fe2 doge day ruin trans try awareness\n",
      "Topic 3:\n",
      "coin dusk fe2 try trans awareness ruin believe day doge\n",
      "Topic 4:\n",
      "coin doge dusk fe2 dot day ruin trans try awareness\n",
      "\n",
      "Cluster 1:\n",
      "Topic 0:\n",
      "sig 258 figure netherland usa comparable ye small holland region\n",
      "Topic 1:\n",
      "sig netherland region holland small ye term usa comparable size\n",
      "Topic 2:\n",
      "netherlands maryland size mainland comparison area islands land kmÂ² state\n",
      "Topic 3:\n",
      "country netherlands kingdom constituent sint caribbean territory netherland bonaire island\n",
      "Topic 4:\n",
      "sig netherland region holland small ye term usa comparable size\n",
      "\n",
      "Cluster 2:\n",
      "Topic 0:\n",
      "ok dang kk awh hi nice oo cool nem viral\n",
      "Topic 1:\n",
      "viral sup yes time cereal nem cool oo nice hi\n",
      "Topic 2:\n",
      "good viral know lolz bad dinner yeah hi nice oo\n",
      "Topic 3:\n",
      "farmr hmm hello lol hi oo nice cool nem viral\n",
      "Topic 4:\n",
      "lol breakfast hipster eat viral hi nice oo cool nem\n",
      "\n",
      "Cluster 3:\n",
      "Topic 0:\n",
      "corn\n",
      "Topic 1:\n",
      "corn\n",
      "Topic 2:\n",
      "corn\n",
      "Topic 3:\n",
      "corn\n",
      "Topic 4:\n",
      "corn\n",
      "\n",
      "Cluster 4:\n",
      "Topic 0:\n",
      "easter town egg mike think hunt color small bit treat\n",
      "Topic 1:\n",
      "leku chop clinic ol gender dick say moe idk think\n",
      "Topic 2:\n",
      "moe easter town ellie dee live trans celebration come community\n",
      "Topic 3:\n",
      "leku day visibility trans egg easter paint awareness celebrate bidens\n",
      "Topic 4:\n",
      "sig leku story tell good life lol work live easter\n",
      "\n",
      "Cluster 5:\n",
      "Topic 0:\n",
      "sig slavery slave white african bad black right iq freedom\n",
      "Topic 1:\n",
      "consent issue involve various medical explore test like context different\n",
      "Topic 2:\n",
      "history past understand historical good people suffering different site ancient\n",
      "Topic 3:\n",
      "history test practice complicated modern ignore lot procedure deeply historical\n",
      "Topic 4:\n",
      "slavery cultural culture society exploitation impact form let appropriation historical\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_topics = 200  # Adjust based on your dataset\n",
    "#vectorizer = CountVectorizer(max_df=0.95, min_df=1, stop_words='english')\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "for cluster in sorted(chat_logs_df['cluster'].unique()):\n",
    "    texts = chat_logs_df[chat_logs_df['cluster'] == cluster]['message_clean']\n",
    "    if len(texts) == 0:\n",
    "        continue  # Skip clusters with no texts\n",
    "    dtm = vectorizer.fit_transform(texts)\n",
    "    lda = LatentDirichletAllocation(n_components=5, random_state=0)  # Adjust n_components as needed\n",
    "    lda.fit(dtm)\n",
    "    \n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    tf_feature_names = vectorizer.get_feature_names_out()\n",
    "    display_topics(lda, tf_feature_names, no_top_words=10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T19:50:32.756640Z",
     "start_time": "2024-04-08T19:50:32.461717Z"
    }
   },
   "id": "bd916270697606f5",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Processing output from Latent Dirichlet Allocation (LDA)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b3db016400fce74"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 topic distribution: [[0.01262468 0.94918605 0.01280977 0.01269663 0.01268287]]\n",
      "Document 1 topic distribution: [[0.00671778 0.00675315 0.00673162 0.00671924 0.9730782 ]]\n",
      "Document 2 topic distribution: [[0.01055997 0.01056068 0.01067255 0.9575465  0.0106603 ]]\n",
      "Document 3 topic distribution: [[0.00742245 0.00744567 0.97018283 0.00741793 0.00753112]]\n",
      "Document 4 topic distribution: [[0.00693061 0.00696375 0.97222228 0.00694487 0.0069385 ]]\n"
     ]
    }
   ],
   "source": [
    "# Example of getting topic distribution for the first 5 documents\n",
    "for i in range(5):\n",
    "    topic_distribution = lda.transform(dtm[i:i+1])\n",
    "    print(f\"Document {i} topic distribution:\", topic_distribution)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T19:50:35.836311Z",
     "start_time": "2024-04-08T19:50:35.817543Z"
    }
   },
   "id": "b457217b1fbfc3cd",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el4651253112288125765917459986\" style=\"background-color:white;\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el4651253112288125765917459986_data = {\"mdsDat\": {\"x\": [-2.3916208744049072, 78.11407470703125, -46.06219482421875, 81.46053314208984, -87.05696868896484], \"y\": [-92.9041748046875, 1.469565749168396, 118.66802215576172, 124.8215560913086, 2.6143994331359863], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [33.84143024774432, 17.289984016842162, 16.951547105928206, 16.363966409626123, 15.553072219859196]}, \"tinfo\": {\"Term\": [\"consent\", \"slave\", \"medical\", \"sig\", \"various\", \"cultural\", \"understand\", \"involve\", \"african\", \"procedure\", \"white\", \"history\", \"ethic\", \"human\", \"site\", \"ancient\", \"appropriation\", \"cruelty\", \"past\", \"society\", \"important\", \"risk\", \"entirely\", \"worth\", \"celebrate\", \"evil\", \"make\", \"genre\", \"artist\", \"country\", \"inherent\", \"racist\", \"dynamic\", \"conversation\", \"middle\", \"society\", \"erasure\", \"yeah\", \"power\", \"simple\", \"legacy\", \"live\", \"east\", \"contribute\", \"real\", \"mark\", \"free\", \"pass\", \"impact\", \"let\", \"cultural\", \"culture\", \"education\", \"social\", \"exploitation\", \"artifact\", \"big\", \"company\", \"costume\", \"crosse\", \"appropriation\", \"especially\", \"injustice\", \"strip\", \"recognize\", \"slavery\", \"form\", \"discussion\", \"historical\", \"complex\", \"sig\", \"history\", \"foster\", \"atrocity\", \"race\", \"honest\", \"significance\", \"oppression\", \"reality\", \"argument\", \"guy\", \"african\", \"93\", \"choice\", \"contemporary\", \"continue\", \"differentiate\", \"economy\", \"evolve\", \"fundamental\", \"nature\", \"number\", \"overlook\", \"solid\", \"throw\", \"32\", \"american\", \"beast\", \"burden\", \"deal\", \"emotionally\", \"extremely\", \"forget\", \"low\", \"minimum\", \"owner\", \"possess\", \"reactionary\", \"make\", \"white\", \"behavior\", \"public\", \"slave\", \"sig\", \"autonomy\", \"black\", \"right\", \"freedom\", \"labor\", \"come\", \"bad\", \"work\", \"honest\", \"slavery\", \"iq\", \"crucial\", \"like\", \"intelligence\", \"form\", \"historical\", \"america\", \"reason\", \"complete\", \"structure\", \"consent\", \"artist\", \"country\", \"genre\", \"lack\", \"various\", \"involve\", \"ah\", \"album\", \"beyonc\\u00e9\", \"cross\", \"decide\", \"expression\", \"historie\", \"huh\", \"music\", \"musical\", \"neverending\", \"root\", \"aim\", \"align\", \"appearance\", \"critical\", \"ethnic\", \"frame\", \"hope\", \"improve\", \"inform\", \"lie\", \"life\", \"important\", \"risk\", \"significant\", \"individual\", \"medical\", \"issue\", \"intention\", \"explore\", \"difference\", \"context\", \"test\", \"like\", \"appropriation\", \"understand\", \"intelligence\", \"different\", \"complex\", \"cultural\", \"historical\", \"slavery\", \"bad\", \"range\", \"talk\", \"entirely\", \"worth\", \"celebrate\", \"evil\", \"absolutely\", \"alright\", \"bleed\", \"death\", \"fatality\", \"infection\", \"separate\", \"wildly\", \"absurd\", \"base\", \"biased\", \"certainly\", \"culturally\", \"dangerous\", \"determine\", \"diverse\", \"entire\", \"label\", \"misinformation\", \"multifacete\", \"nope\", \"simplistically\", \"value\", \"barely\", \"cover\", \"educational\", \"complicated\", \"ignore\", \"modern\", \"history\", \"lot\", \"deeply\", \"procedure\", \"practice\", \"test\", \"human\", \"medical\", \"slave\", \"sig\", \"historical\", \"slavery\", \"foster\", \"people\", \"high\", \"iq\", \"discussion\", \"control\", \"come\", \"factor\", \"include\", \"continent\", \"flawed\", \"cruelty\", \"achievement\", \"building\", \"common\", \"creation\", \"dark\", \"glorify\", \"heritage\", \"insight\", \"invaluable\", \"level\", \"offer\", \"old\", \"plus\", \"preserving\", \"share\", \"testament\", \"yes\", \"bark\", \"basic\", \"decency\", \"defensible\", \"definition\", \"inhumane\", \"thrive\", \"treatment\", \"tree\", \"twist\", \"civilization\", \"construction\", \"ethic\", \"site\", \"ancient\", \"past\", \"understand\", \"procedure\", \"good\", \"suffering\", \"history\", \"historical\", \"human\", \"people\", \"medical\", \"different\", \"slavery\", \"exploitation\", \"labor\", \"thing\", \"build\", \"reason\", \"pyramid\", \"ve\", \"rational\", \"claim\", \"mean\", \"aspect\", \"time\", \"relate\", \"connection\"], \"Freq\": [4.0, 5.0, 4.0, 7.0, 3.0, 8.0, 5.0, 3.0, 3.0, 3.0, 3.0, 8.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.3804363583670005, 2.3804363583670005, 2.380436334442353, 2.3804355720681203, 2.3804326803313742, 3.868572378836415, 1.6365484227984612, 1.6365481665131898, 1.6365480343371734, 1.6365480343371734, 1.6365479174423283, 1.6365478363344175, 1.6365477835757691, 1.636547473483143, 1.6365468242597045, 1.636545974424706, 1.63654272298933, 1.63654272298933, 3.1251303588869206, 3.1244538792811167, 6.100739914562691, 3.8691169601712336, 2.380509987518661, 2.380736031672532, 3.1296687159481658, 0.8926600966394647, 0.8926600966394647, 0.8926600966394647, 0.8926600966394647, 0.8926600966394647, 3.1238609922039724, 2.380679562457794, 1.6368140623226222, 1.6365399262436444, 1.6364890839282376, 6.848840748458894, 3.124823536927638, 2.381133449760377, 3.123816811017108, 2.380530290810949, 2.3778993049602817, 2.3799864221962514, 1.6376093854769327, 1.6366614373595307, 1.636654645146368, 1.6366340511732576, 1.6366122744530065, 1.636566396502699, 1.3330874331877518, 1.3330871613168473, 1.333086094091709, 1.9396262507389475, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271378344864217, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 0.7271371361968123, 1.3333476309403285, 1.94074710019216, 1.3334349030430552, 1.3334101284961504, 2.5471178926330627, 3.1591942378935767, 1.3333024217602232, 1.3342040044429437, 1.3339650964717336, 1.3339168377872401, 1.3326281610190993, 1.3333314616876288, 1.335299676535405, 1.333190449030796, 1.3330155070040106, 3.1547281322107916, 1.3339191099864347, 1.3334065846068592, 1.3334001257498929, 1.3334065886979611, 1.333045327224637, 1.3327330454286075, 0.7273093381835425, 0.727294171952557, 0.7272859164727736, 0.7272766030004012, 3.763074669127941, 1.3349714234523813, 1.3349714234523813, 1.3349714234523813, 1.3349708830513878, 1.942305435044277, 1.9424120536497744, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.7281650538587451, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 0.728164929659015, 1.3350538342504656, 1.3350920761949836, 1.335332565047339, 1.3353173854305853, 1.9419722868978906, 1.94303135797377, 1.3355429956175071, 1.33614302207947, 1.3353075496389162, 1.3357234780916576, 1.3359878834276315, 1.3357926070728952, 1.3353482007140967, 1.3347441193030907, 1.335326972636387, 1.335567961227632, 1.3355293714617624, 1.3350204941673212, 1.3348124733479485, 1.3303478898264989, 0.7285405597550202, 0.7284769551462701, 0.7284025266319132, 1.3119566020761537, 1.3119561470917052, 1.3119552891794395, 1.311953481792033, 0.7156118694627497, 0.7156118694627497, 0.7156118694627497, 0.7156118694627497, 0.7156118694627497, 0.7156118694627497, 0.7156118694627497, 0.7156118694627497, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156117482327933, 0.7156104884295601, 0.7156104884295601, 0.7156104884295601, 1.3123037749309934, 1.312260757077753, 1.3122897099095683, 2.5068731208328727, 1.312164590519377, 1.3121391632333097, 1.3121544331089146, 1.3127786738563185, 1.3131119072924493, 1.3119304810987686, 1.3119656186549191, 1.3116236465577116, 1.3120567647930947, 1.3121316202638205, 1.3082328725059849, 0.7159872875469432, 0.7158963635036113, 0.7158870964337214, 0.715876475624231, 0.7158018200128546, 0.7157709505276075, 0.7157685867943735, 0.715750430614649, 0.7157356184673829, 0.7157325649847192, 0.7157240647320876, 1.2936016630863831, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055998656473467, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055996894308734, 0.7055995207119223, 0.7055995207119223, 1.293963871314214, 1.2942919332667346, 1.2942837306383979, 1.8835162572474786, 1.8824090514042855, 1.2936672128339972, 1.2950634377389576, 1.2945412809960344, 1.8835492713945703, 1.88234288976516, 1.2940954981077546, 1.29501850837261, 1.2934075862234986, 1.294339936138956, 1.2940753124375641, 0.7066407776844517, 0.7061673937039274, 0.7060674916331067, 0.7059413955574924, 0.7059372813395428, 0.7058341098912904, 0.7058276999469517, 0.7058057211460976, 0.7057904519923596, 0.7057818752254142, 0.7057645525046997, 0.7057645525046997, 0.7057509844539223, 0.7057472274889832], \"Total\": [4.0, 5.0, 4.0, 7.0, 3.0, 8.0, 5.0, 3.0, 3.0, 3.0, 3.0, 8.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.859860874374445, 2.859860874374445, 2.859860869203448, 2.859860720466684, 2.8598601588701134, 4.935713943296177, 2.115972979050246, 2.115972929169041, 2.1159729030464303, 2.1159729030464303, 2.115972880651803, 2.115972863818989, 2.1159728547210537, 2.115972793833902, 2.1159726664115945, 2.115972504335686, 2.1159718710961473, 2.1159718710961473, 4.191919550213367, 4.200119530568043, 8.381096772386632, 5.550965113736948, 3.456220536833223, 3.4658664877747416, 4.798659804532543, 1.3720850080711509, 1.3720850080711509, 1.3720850080711509, 1.3720850080711509, 1.3720850080711509, 4.817275479113076, 4.072661818303987, 2.704030511705425, 2.7039729820342693, 2.703962351667969, 13.936224955439734, 6.0188949943940955, 4.669087507741033, 8.985836839822644, 5.863798816818187, 7.68862635512576, 8.221820770916604, 3.319312914945826, 2.712340462762971, 2.7219427012380817, 3.3278889589246585, 3.31079313835222, 2.722782324850236, 1.8400984328933676, 1.8400984363311021, 1.8400984619677399, 3.1898013259448406, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483227188221, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 1.2341483404163325, 2.436447787952372, 3.7859512528092765, 2.5839062136691444, 2.5839116687306927, 5.732060667641537, 7.68862635512576, 3.0349096224302485, 3.171794546942092, 3.1719057280777436, 3.1719217370190362, 3.1719405625917436, 3.180236460371345, 3.1902009163720777, 3.327849572173378, 3.3278889589246585, 13.936224955439734, 3.7868482261096386, 3.915835339574175, 4.541228671410671, 5.137729651639394, 6.0188949943940955, 8.985836839822644, 2.5743287327530626, 2.5659119154461627, 1.9779997101872875, 1.9780035804286564, 4.8570638200318275, 1.8418103716648393, 1.8418103716648393, 1.8418103716648393, 1.8418103811360056, 3.0545673983870856, 3.192360015218122, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.2350043024410238, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 1.235004299726448, 2.4298149044112565, 2.4381575983813137, 2.5856156113277016, 2.585619204038635, 4.817316384467303, 4.9826130158177, 3.1735903477054483, 3.925676486019889, 3.935483180270761, 4.37583708841303, 4.383949085986045, 4.541228671410671, 4.817275479113076, 5.093428846724003, 5.137729651639394, 5.707655640380002, 5.863798816818187, 8.381096772386632, 8.985836839822644, 13.936224955439734, 3.1902009163720777, 2.7227074701326686, 1.8313538548482309, 1.8208883785141425, 1.8208883989218698, 1.8208884394819655, 1.8208885297826427, 1.2245433158081904, 1.2245433158081904, 1.2245433158081904, 1.2245433158081904, 1.2245433158081904, 1.2245433158081904, 1.2245433158081904, 1.2245433158081904, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433239900687, 1.2245433829978016, 1.2245433829978016, 1.2245433829978016, 2.5646892664369214, 2.564700015759132, 3.0336390110687455, 8.221820770916604, 3.3086117693129338, 3.3086181340174026, 3.60369260580315, 3.759408997047692, 4.383949085986045, 4.484543004003368, 4.817316384467303, 5.732060667641537, 7.68862635512576, 8.985836839822644, 13.936224955439734, 3.319312914945826, 4.493908593193812, 1.9683614894702894, 3.7868482261096386, 4.669087507741033, 2.575177420337473, 3.180236460371345, 2.57518643431064, 2.556378097534885, 1.8304916260741426, 1.9684026262831464, 1.8042017788311084, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.216200049004243, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000615864388, 1.2162000707833724, 1.2162000707833724, 2.40054191738334, 2.4101310518526384, 2.4101313130200923, 5.083012118847504, 5.093428846724003, 3.60369260580315, 3.613271154363228, 3.751081598997259, 8.221820770916604, 8.985836839822644, 4.484543004003368, 4.493908593193812, 4.817316384467303, 5.707655640380002, 13.936224955439734, 4.798659804532543, 3.1719405625917436, 1.9599612900008054, 2.4184846174770076, 2.5659119154461627, 1.8221432562303137, 1.8221434654765447, 1.8125425538023654, 1.9600362356528946, 2.4184913103991845, 1.9600433297817044, 1.9600433297817044, 1.9600467972276963, 1.9600478259789136], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.965, -4.965, -4.965, -4.965, -4.965, -4.4794, -5.3396, -5.3396, -5.3396, -5.3396, -5.3396, -5.3397, -5.3397, -5.3397, -5.3397, -5.3397, -5.3397, -5.3397, -4.6928, -4.693, -4.0238, -4.4792, -4.9649, -4.9648, -4.6913, -5.9458, -5.9458, -5.9458, -5.9458, -5.9458, -4.6932, -4.9649, -5.3395, -5.3397, -5.3397, -3.9082, -4.6929, -4.9647, -4.6932, -4.9649, -4.966, -4.9651, -5.339, -5.3396, -5.3396, -5.3396, -5.3396, -5.3396, -4.8732, -4.8732, -4.8732, -4.4982, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -5.4793, -4.873, -4.4976, -4.8729, -4.8729, -4.2257, -4.0104, -4.873, -4.8723, -4.8725, -4.8726, -4.8735, -4.873, -4.8715, -4.8731, -4.8732, -4.0118, -4.8726, -4.8729, -4.8729, -4.8729, -4.8732, -4.8734, -5.4791, -5.4791, -5.4791, -5.4791, -3.8157, -4.852, -4.852, -4.852, -4.852, -4.477, -4.477, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -5.4581, -4.8519, -4.8519, -4.8517, -4.8517, -4.4772, -4.4767, -4.8516, -4.8511, -4.8518, -4.8514, -4.8512, -4.8514, -4.8517, -4.8522, -4.8517, -4.8516, -4.8516, -4.852, -4.8521, -4.8555, -5.4576, -5.4577, -5.4578, -4.8341, -4.8341, -4.8341, -4.8341, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -5.4403, -4.8339, -4.8339, -4.8339, -4.1866, -4.834, -4.834, -4.834, -4.8335, -4.8332, -4.8341, -4.8341, -4.8344, -4.834, -4.834, -4.837, -5.4397, -5.4399, -5.4399, -5.4399, -5.44, -5.44, -5.44, -5.4401, -5.4401, -5.4401, -5.4401, -4.7974, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -5.4035, -4.7971, -4.7968, -4.7969, -4.4217, -4.4223, -4.7973, -4.7963, -4.7967, -4.4217, -4.4223, -4.797, -4.7963, -4.7975, -4.7968, -4.797, -5.402, -5.4027, -5.4029, -5.403, -5.403, -5.4032, -5.4032, -5.4032, -5.4032, -5.4033, -5.4033, -5.4033, -5.4033, -5.4033], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9, 0.9, 0.9, 0.9, 0.9, 0.8399, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.8266, 0.7898, 0.7876, 0.7659, 0.7225, 0.7106, 0.7079, 0.6561, 0.6536, 0.6536, 0.6536, 0.6536, 0.6536, 0.6503, 0.5466, 0.5815, 0.5813, 0.5813, 0.3731, 0.428, 0.4101, 0.0269, 0.182, -0.09, -0.1562, 0.377, 0.5783, 0.5748, 0.3738, 0.3789, 0.5744, 1.4327, 1.4327, 1.4327, 1.2576, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.226, 1.1522, 1.0868, 1.0935, 1.0935, 0.9439, 0.8656, 0.9325, 0.8891, 0.8889, 0.8888, 0.8879, 0.8858, 0.8841, 0.8403, 0.8401, 0.2695, 0.7116, 0.6778, 0.5296, 0.4062, 0.2476, -0.1534, 0.4911, 0.4943, 0.7545, 0.7545, 1.5196, 1.453, 1.453, 1.453, 1.453, 1.322, 1.278, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.2465, 1.176, 1.1726, 1.114, 1.114, 0.8663, 0.8331, 0.9093, 0.6971, 0.6939, 0.5882, 0.5865, 0.5511, 0.4918, 0.4356, 0.4274, 0.3224, 0.2953, -0.0622, -0.132, -0.5742, 0.298, 0.4564, 0.8529, 1.4823, 1.4823, 1.4823, 1.4823, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.2729, 1.14, 1.14, 0.9721, 0.6223, 0.8852, 0.8852, 0.7998, 0.758, 0.6045, 0.581, 0.5094, 0.3353, 0.0419, -0.1139, -0.5557, 0.2762, -0.0269, 0.7987, 0.1443, -0.0652, 0.5298, 0.3187, 0.5297, 0.5371, 0.8711, 0.7984, 1.5282, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.3165, 1.2429, 1.2392, 1.2392, 0.8681, 0.8655, 0.8364, 0.8349, 0.797, 0.3873, 0.2978, 0.6181, 0.6167, 0.546, 0.3771, -0.5158, -0.0547, 0.3587, 0.8399, 0.6295, 0.5704, 0.9125, 0.9125, 0.9178, 0.8395, 0.6293, 0.8395, 0.8395, 0.8395, 0.8394]}, \"token.table\": {\"Topic\": [2, 2, 4, 4, 5, 1, 2, 3, 3, 3, 3, 4, 1, 2, 4, 2, 2, 5, 3, 1, 3, 2, 1, 3, 1, 5, 1, 4, 2, 3, 5, 1, 2, 3, 4, 5, 4, 5, 2, 1, 2, 3, 4, 1, 1, 2, 5, 4, 2, 4, 5, 5, 2, 4, 4, 2, 5, 1, 5, 1, 2, 4, 5, 1, 1, 2, 1, 2, 3, 4, 5, 1, 4, 1, 5, 3, 5, 5, 2, 1, 2, 3, 4, 5, 2, 4, 2, 1, 1, 3, 4, 1, 1, 3, 4, 5, 3, 3, 1, 1, 2, 5, 5, 1, 3, 5, 4, 1, 3, 4, 4, 5, 2, 4, 5, 3, 1, 4, 5, 5, 4, 1, 2, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 4, 1, 1, 2, 1, 4, 4, 2, 4, 4, 1, 1, 2, 3, 4, 5, 3, 4, 2, 1, 2, 5, 1, 3, 4, 3, 2, 1, 3, 4, 4, 1, 4, 2, 1, 2, 3, 4, 1, 3, 4, 3, 1, 1, 2, 5, 2, 3, 5, 2, 3, 4, 5, 2, 5, 1, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 3, 1, 4, 5, 1, 4, 1, 5, 3, 5, 3, 1, 4, 5, 1, 3, 4, 3, 1, 5, 1, 5, 5, 1, 2, 3, 4, 1, 3, 5, 5, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 5, 3, 1, 1, 4, 5, 3, 3, 1, 2, 3, 1, 1, 4, 2, 2, 4, 1, 2, 4, 5, 3, 4, 5, 1, 2, 4, 2, 3, 4, 4, 3, 3, 2, 3, 4, 2, 5, 5, 1, 3, 2, 2, 1, 1, 3, 4, 5, 1, 2, 4, 5, 5, 2, 1, 1, 3, 4, 5, 5, 3, 4, 5, 1, 2, 2, 5, 1, 2, 1, 1, 3, 4, 5, 2, 1, 2, 1, 2, 5, 1, 5, 1, 5, 1, 2, 5, 3, 4, 3, 4, 5, 1, 2, 3, 4, 1, 3, 5, 1, 3, 1, 4, 2, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 2, 1, 5, 2, 1, 5, 1, 2, 1, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 5, 5, 2, 1, 5, 5, 5, 5, 1, 3, 5, 4, 2, 3, 2, 5, 1, 2, 4, 4, 1, 2, 4, 1, 5], \"Freq\": [0.8102753674348872, 0.81027537905412, 0.8166309734335585, 0.8166309679771773, 0.8222331522011895, 0.31349914863546974, 0.6269982972709395, 0.8097137783435, 0.8097137801232747, 0.8097137783435, 0.8097137801232747, 0.8166309734335585, 0.38845077836293684, 0.38845077836293684, 0.38845077836293684, 0.8102753674348872, 0.41491515196610507, 0.41491515196610507, 0.8097137801232747, 0.6227586553867457, 0.20758621846224853, 0.5434491874216575, 0.7288178167661635, 0.5429440594886462, 0.5101928027843001, 0.5101928027843001, 0.7373705578106764, 0.3686852789053382, 0.3294991035677811, 0.3294991035677811, 0.3294991035677811, 0.3134598811215966, 0.3134598811215966, 0.3134598811215966, 0.81663092862574, 0.8222331436947778, 0.8166309679771773, 0.8222331436947778, 0.8102753674348872, 0.38701095059483637, 0.38701095059483637, 0.8097137783435, 0.8166309679771773, 0.7288178167661635, 0.3152789328565099, 0.3152789328565099, 0.3152789328565099, 0.8166309734335585, 0.4134820592918272, 0.4134820592918272, 0.4134820592918272, 0.8222331522011895, 0.8102753674348872, 0.5491824640747873, 0.8166309679771773, 0.81027537905412, 0.8222331374770314, 0.5101946493692738, 0.5101946493692738, 0.3144420273337894, 0.3144420273337894, 0.3144420273337894, 0.8222331522011895, 0.7288178167661635, 0.5055612469757716, 0.5055612469757716, 0.3410758217460877, 0.17053791087304385, 0.17053791087304385, 0.17053791087304385, 0.17053791087304385, 0.3899107829890374, 0.3899107829890374, 0.5101916324417066, 0.5101916324417066, 0.8235428127386205, 0.20588570318465513, 0.8222331374770314, 0.81027537905412, 0.22852770333885225, 0.22852770333885225, 0.22852770333885225, 0.22852770333885225, 0.22852770333885225, 0.5463013246035444, 0.5463013246035444, 0.81027537905412, 0.9451917367879894, 0.38832275869712757, 0.38832275869712757, 0.38832275869712757, 0.6993347563001711, 0.7288178167661635, 0.5429440594886462, 0.81663092862574, 0.8222331522011895, 0.8097137801232747, 0.8097137783435, 0.7288178167661635, 0.5107467057635495, 0.25537335288177476, 0.25537335288177476, 0.5542617304411882, 0.7158967570650563, 0.11931612617750938, 0.11931612617750938, 0.8166309679771773, 0.72059541323746, 0.180148853309365, 0.180148853309365, 0.8166309679771773, 0.8222331522011895, 0.8102753674348872, 0.8166309734335585, 0.8222331436947778, 0.8097137783435, 0.6044819676943355, 0.30224098384716774, 0.8222331436947778, 0.8222331436947778, 0.8166309679771773, 0.5081968105025416, 0.2540984052512708, 0.2540984052512708, 0.3504065637475713, 0.17520328187378564, 0.17520328187378564, 0.17520328187378564, 0.17520328187378564, 0.81027537905412, 0.42834922170212797, 0.21417461085106398, 0.21417461085106398, 0.21417461085106398, 0.8166309679771773, 0.6993347199288952, 0.9451917095900825, 0.81027537905412, 0.578666777390458, 0.289333388695229, 0.81663092862574, 0.8102753674348872, 0.8166309679771773, 0.5491824824627674, 0.9451916540530209, 0.4910793209029265, 0.24553966045146325, 0.24553966045146325, 0.41657260502663035, 0.41657260502663035, 0.8097137801232747, 0.5491824368399799, 0.81027537905412, 0.6251745533547449, 0.208391517784915, 0.208391517784915, 0.5094663320124304, 0.2547331660062152, 0.2547331660062152, 0.8097137783435, 0.8102753674348872, 0.3883213994437235, 0.3883213994437235, 0.3883213994437235, 0.8166309734335585, 0.508026145996492, 0.508026145996492, 0.8102753674348872, 0.49843036018972803, 0.16614345339657602, 0.16614345339657602, 0.16614345339657602, 0.6025343350410342, 0.3012671675205171, 0.3012671675205171, 0.8097137801232747, 0.9451921489693198, 0.3152662905673699, 0.3152662905673699, 0.3152662905673699, 0.81027537905412, 0.5429440594886462, 0.8222331522011895, 0.27675753002717324, 0.27675753002717324, 0.27675753002717324, 0.27675753002717324, 0.5434491798502095, 0.8222331522011895, 0.5080367632416505, 0.5080367632416505, 0.33385872161676283, 0.11128624053892094, 0.11128624053892094, 0.11128624053892094, 0.2225724810778419, 0.8097137783435, 0.24325512021311446, 0.12162756010655723, 0.12162756010655723, 0.3648826803196717, 0.24325512021311446, 0.6009815906376457, 0.30049079531882283, 0.8097137801232747, 0.8097137783435, 0.4459763231648337, 0.22298816158241686, 0.22298816158241686, 0.38990914877193056, 0.38990914877193056, 0.7156625894328772, 0.23855419647762574, 0.4115539822331857, 0.4115539822331857, 0.8097137801232747, 0.39117844146931935, 0.39117844146931935, 0.39117844146931935, 0.38675455319872293, 0.38675455319872293, 0.8166309734335585, 0.8097137801232747, 0.6993347186644079, 0.8222331436947778, 0.7396366244176014, 0.3698183122088007, 0.8222331522011895, 0.38927700280255534, 0.19463850140127767, 0.19463850140127767, 0.19463850140127767, 0.3151005298220088, 0.3151005298220088, 0.3151005298220088, 0.8222331522011895, 0.3132478778185905, 0.626495755637181, 0.26407184557996793, 0.26407184557996793, 0.26407184557996793, 0.26407184557996793, 0.20069790626432774, 0.20069790626432774, 0.40139581252865547, 0.20069790626432774, 0.20069790626432774, 0.8166309679771773, 0.3152644194514526, 0.3152644194514526, 0.3152644194514526, 0.5429440566966576, 0.9451916980069808, 0.7142653865363366, 0.23808846217877888, 0.8222331522011895, 0.8097137801232747, 0.8097137801232747, 0.4404094452655534, 0.2202047226327767, 0.2202047226327767, 0.9451917055260923, 0.6044831305231438, 0.3022415652615719, 0.8102753674348872, 0.4104335848872901, 0.4104335848872901, 0.9451918661050391, 0.41348091502340145, 0.41348091502340145, 0.41348091502340145, 0.41516891156426694, 0.20758445578213347, 0.20758445578213347, 0.699334893629963, 0.8102753674348872, 0.8166309679771773, 0.32963711118934413, 0.32963711118934413, 0.32963711118934413, 0.8166309679771773, 0.8097137783435, 0.8097137783435, 0.81027537905412, 0.8097137783435, 0.8166309679771773, 0.81027537905412, 0.8222331522011895, 0.8222331522011895, 0.7345427439228026, 0.3672713719614013, 0.81027537905412, 0.8102753674348872, 0.9451921489693198, 0.39346748605696213, 0.19673374302848107, 0.19673374302848107, 0.39346748605696213, 0.4450468803546812, 0.2225234401773406, 0.2225234401773406, 0.2225234401773406, 0.8222331522011895, 0.8102753674348872, 0.9451916880034426, 0.26599925700696886, 0.26599925700696886, 0.26599925700696886, 0.26599925700696886, 0.8222331522011895, 0.2774931464436411, 0.2774931464436411, 0.2774931464436411, 0.38701013355121183, 0.38701013355121183, 0.5488042702354917, 0.5488042702354917, 0.7347693245307094, 0.3673846622653547, 0.6993347186644079, 0.7345629385233026, 0.3672814692616513, 0.5517111848779453, 0.5517111848779453, 0.8102753674348872, 0.945191793706736, 0.5434491884369478, 0.38972499171941344, 0.38972499171941344, 0.38972499171941344, 0.7396552687822291, 0.36982763439111455, 0.5101919002211616, 0.5101919002211616, 0.3152678817494446, 0.3152678817494446, 0.3152678817494446, 0.4101457595127966, 0.4101457595127966, 0.8097137783435, 0.8166309734335585, 0.8222331522011895, 0.26012448877381905, 0.39018673316072855, 0.13006224438690953, 0.13006224438690953, 0.6040848571395188, 0.3020424285697594, 0.3020424285697594, 0.3867550905938817, 0.3867550905938817, 0.9451916880034426, 0.8166309679771773, 0.4149151969272842, 0.4149151969272842, 0.34891466018326395, 0.5233719902748959, 0.17445733009163197, 0.5022881032978509, 0.21526632998479323, 0.0717554433282644, 0.0717554433282644, 0.0717554433282644, 0.5770562735335195, 0.28852813676675976, 0.8104197378441897, 0.20260493446104744, 0.81027537905412, 0.7396523609105546, 0.3698261804552773, 0.5055602577743, 0.5055602577743, 0.26658977513774174, 0.26658977513774174, 0.26658977513774174, 0.26658977513774174, 0.5460441177725714, 0.5460441177725714, 0.2281048388989395, 0.2281048388989395, 0.2281048388989395, 0.2281048388989395, 0.8222331522011895, 0.5102141583620711, 0.5102141583620711, 0.8222331436947778, 0.81027537905412, 0.5101928027843001, 0.5101928027843001, 0.8222331436947778, 0.8222331436947778, 0.8222331436947778, 0.3926627936083493, 0.19633139680417466, 0.3926627936083493, 0.8166309679771773, 0.32737860049447054, 0.6547572009889411, 0.5488042072134371, 0.5488042072134371, 0.26413440988126125, 0.5282688197625225, 0.26413440988126125, 0.8166309734335585, 0.6009887035530348, 0.3004943517765174, 0.5491824763077683, 0.945191676334638, 0.8222331522011895], \"Term\": [\"32\", \"93\", \"absolutely\", \"absurd\", \"achievement\", \"african\", \"african\", \"ah\", \"aim\", \"album\", \"align\", \"alright\", \"america\", \"america\", \"america\", \"american\", \"ancient\", \"ancient\", \"appearance\", \"appropriation\", \"appropriation\", \"argument\", \"artifact\", \"artist\", \"aspect\", \"aspect\", \"atrocity\", \"atrocity\", \"autonomy\", \"autonomy\", \"autonomy\", \"bad\", \"bad\", \"bad\", \"barely\", \"bark\", \"base\", \"basic\", \"beast\", \"behavior\", \"behavior\", \"beyonc\\u00e9\", \"biased\", \"big\", \"black\", \"black\", \"black\", \"bleed\", \"build\", \"build\", \"build\", \"building\", \"burden\", \"celebrate\", \"certainly\", \"choice\", \"civilization\", \"claim\", \"claim\", \"come\", \"come\", \"come\", \"common\", \"company\", \"complete\", \"complete\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complicated\", \"complicated\", \"connection\", \"connection\", \"consent\", \"consent\", \"construction\", \"contemporary\", \"context\", \"context\", \"context\", \"context\", \"context\", \"continent\", \"continent\", \"continue\", \"contribute\", \"control\", \"control\", \"control\", \"conversation\", \"costume\", \"country\", \"cover\", \"creation\", \"critical\", \"cross\", \"crosse\", \"crucial\", \"crucial\", \"crucial\", \"cruelty\", \"cultural\", \"cultural\", \"cultural\", \"culturally\", \"culture\", \"culture\", \"culture\", \"dangerous\", \"dark\", \"deal\", \"death\", \"decency\", \"decide\", \"deeply\", \"deeply\", \"defensible\", \"definition\", \"determine\", \"difference\", \"difference\", \"difference\", \"different\", \"different\", \"different\", \"different\", \"different\", \"differentiate\", \"discussion\", \"discussion\", \"discussion\", \"discussion\", \"diverse\", \"dynamic\", \"east\", \"economy\", \"education\", \"education\", \"educational\", \"emotionally\", \"entire\", \"entirely\", \"erasure\", \"especially\", \"especially\", \"especially\", \"ethic\", \"ethic\", \"ethnic\", \"evil\", \"evolve\", \"exploitation\", \"exploitation\", \"exploitation\", \"explore\", \"explore\", \"explore\", \"expression\", \"extremely\", \"factor\", \"factor\", \"factor\", \"fatality\", \"flawed\", \"flawed\", \"forget\", \"form\", \"form\", \"form\", \"form\", \"foster\", \"foster\", \"foster\", \"frame\", \"free\", \"freedom\", \"freedom\", \"freedom\", \"fundamental\", \"genre\", \"glorify\", \"good\", \"good\", \"good\", \"good\", \"guy\", \"heritage\", \"high\", \"high\", \"historical\", \"historical\", \"historical\", \"historical\", \"historical\", \"historie\", \"history\", \"history\", \"history\", \"history\", \"history\", \"honest\", \"honest\", \"hope\", \"huh\", \"human\", \"human\", \"human\", \"ignore\", \"ignore\", \"impact\", \"impact\", \"important\", \"important\", \"improve\", \"include\", \"include\", \"include\", \"individual\", \"individual\", \"infection\", \"inform\", \"inherent\", \"inhumane\", \"injustice\", \"injustice\", \"insight\", \"intelligence\", \"intelligence\", \"intelligence\", \"intelligence\", \"intention\", \"intention\", \"intention\", \"invaluable\", \"involve\", \"involve\", \"iq\", \"iq\", \"iq\", \"iq\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"label\", \"labor\", \"labor\", \"labor\", \"lack\", \"legacy\", \"let\", \"let\", \"level\", \"lie\", \"life\", \"like\", \"like\", \"like\", \"live\", \"lot\", \"lot\", \"low\", \"make\", \"make\", \"mark\", \"mean\", \"mean\", \"mean\", \"medical\", \"medical\", \"medical\", \"middle\", \"minimum\", \"misinformation\", \"modern\", \"modern\", \"modern\", \"multifacete\", \"music\", \"musical\", \"nature\", \"neverending\", \"nope\", \"number\", \"offer\", \"old\", \"oppression\", \"oppression\", \"overlook\", \"owner\", \"pass\", \"past\", \"past\", \"past\", \"past\", \"people\", \"people\", \"people\", \"people\", \"plus\", \"possess\", \"power\", \"practice\", \"practice\", \"practice\", \"practice\", \"preserving\", \"procedure\", \"procedure\", \"procedure\", \"public\", \"public\", \"pyramid\", \"pyramid\", \"race\", \"race\", \"racist\", \"range\", \"range\", \"rational\", \"rational\", \"reactionary\", \"real\", \"reality\", \"reason\", \"reason\", \"reason\", \"recognize\", \"recognize\", \"relate\", \"relate\", \"right\", \"right\", \"right\", \"risk\", \"risk\", \"root\", \"separate\", \"share\", \"sig\", \"sig\", \"sig\", \"sig\", \"significance\", \"significance\", \"significance\", \"significant\", \"significant\", \"simple\", \"simplistically\", \"site\", \"site\", \"slave\", \"slave\", \"slave\", \"slavery\", \"slavery\", \"slavery\", \"slavery\", \"slavery\", \"social\", \"social\", \"society\", \"society\", \"solid\", \"strip\", \"strip\", \"structure\", \"structure\", \"suffering\", \"suffering\", \"suffering\", \"suffering\", \"talk\", \"talk\", \"test\", \"test\", \"test\", \"test\", \"testament\", \"thing\", \"thing\", \"thrive\", \"throw\", \"time\", \"time\", \"treatment\", \"tree\", \"twist\", \"understand\", \"understand\", \"understand\", \"value\", \"various\", \"various\", \"ve\", \"ve\", \"white\", \"white\", \"white\", \"wildly\", \"work\", \"work\", \"worth\", \"yeah\", \"yes\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 1, 2, 4, 3]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el4651253112288125765917459986\", ldavis_el4651253112288125765917459986_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el4651253112288125765917459986\", ldavis_el4651253112288125765917459986_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el4651253112288125765917459986\", ldavis_el4651253112288125765917459986_data);\n            })\n         });\n}\n</script>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.lda_model\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "# panel = pyLDAvis.lda_model.prepare(lda, dtm, vectorizer, mds='pcoa')\n",
    "panel = pyLDAvis.lda_model.prepare(lda, dtm, vectorizer, mds='tsne')\n",
    "pyLDAvis.display(panel)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T19:53:57.470090Z",
     "start_time": "2024-04-08T19:53:56.112622Z"
    }
   },
   "id": "cd6f773bb287e09d",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d08c53f5194ef2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
